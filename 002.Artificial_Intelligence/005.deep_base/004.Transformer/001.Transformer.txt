

//============================================== 
//============================================== 

深度学习还有一种基本模型 Transformer，
		//Transformer 发源于 NLP，后来也引入到了 "图像处理" 中。


Transformer是一种 "注意力机制驱动的模型"，
		它引入了 "自注意力机制"，
		允许模型在处理序列数据时关注不同位置的信息。
		Transformer的架构 "不依赖于序列的顺序" ，
		允许 "并行处理输入序列"。



用 "自注意力机制"，能够同时 "关注序列中的所有位置"，
不依赖于序列的顺序。

适用于各种 "序列任务"，如机器翻译、语言建模等。



