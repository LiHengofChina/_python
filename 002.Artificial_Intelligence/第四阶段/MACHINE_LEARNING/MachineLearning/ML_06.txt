

 //====================================
        它在人工智能发展过程中起到了决定性作用的。
        
 //====================================
        当前所学的都是传统的 "机器学习"
				线性回归
                岭回归/Lasso回归
				多项式回归
                决策树-回归
				逻辑回归
                决策树-分类       

                支持向量机
                朴素贝叶斯
                高斯混合模型
                k-nn
				kmiss
                ......
                //=================== "传统的机器学习"
                上面这些都是 "传统的机器学习"
                它们的核心都是以 "算法" 为核心 
                为了解决需求：设计一个算法出来。
                以 "算法" 为核心，就意味着，它跳不出 "算法这个圈"
                
                如：两个双包胎，看上去很像，但它深层次的东西有很多是不一样的。
                
                 以 "算法" 为核心
                 传统的机器学习 它只能学习到 "数据浅层特征"，
                 它没法跳出这个"算法"的核心

                 所以它的精度也就受到限制，
                 于是转换一下 "思路"
				 以 "数据为核心"，这就是深度学习
                 深度学习：如神经网络，
                  		它有个 "万能近似定理"，只要我的 "神经元足够的多"
						那我这个什么都能干
				
                 同样一个结构，同样一个模型，你把 "线性分布"的数据给我，
                 			 我能学习到 "线性分布的规律"
                             你把非线性的给我，我能学习到 "非线性分布的规律"
							 甚至：
                             	你把 "图像给我" ，我能学习到 "图像是什么"
								你把 "一段语音给我" 我能学习到语音什么
                                你把 "一段文字给我" 我能学习到文字的内容是什么
                  //=============================================== 什么叫 "神经网络"
	               生物学中有 "神经网络" ，一个一个的 "神经元" 组成的 "级联网络"


				   一个 "康耐尔心理大学" 的教授 费朗克*伯森*布拉特，在1937左右，提出了 感知机，
                   感知机也叫（神经元），它是对 "人类大脑去做了一个模仿"。
                   模仿出来在 "人工智能" 这个层面叫 "感知机"

				   深度学习：以 "算法" 和 "计算" 为核心的。 
                   		//同一个算法，不同的数据，不同的一个模型，它能学到不同的规律。
                  //=============================================== "感知机" 与 "分类任务"
	              当发现 感知机也叫 它也能做 "简单的分类任务"时  掀起了 "第一波AI浪潮"

				  感知机无法解决 "异或问题" （线性不可分）
                  					//线性可分:用 "一条直接" 把类别分出来，如：
                  					a  a
                                    _______
                                    b  b
                  					//线性不可分：这里一条直接就分不了了
                  					a  b
                                    b  a
                                    //==================================
                                    因为感知机就是 "一个线性模型"，y = w't * x + b
                                     "第一波AI浪潮" 跌落
		         //==============================================8年之后
                 提出了 "多层感知机串联" ，提出了 "多层感知机" 和神经网络
                 在理解上能够解决 "线性不可分" 的问题
                 //=================
                 "第二波AI浪潮" 掀起
                 由于当时在80年代，由于算力不够，算不出来
                 浪潮又下去了
                 //============================（1）机器学习
                 在同一时期："支持向量机" 的出现，解决了线性不可分的问题，
                 属于传统的 "机器学习"
                 //============================（2）深度学习
				 1998年，YanLecun 2018年 "图灵奖（计算机界的诺了贝尔）" 的获得者，（神经网络奠基人）
                 他提出了CNN（卷积神经网络）, 基于CNN提出 Lenet5 //5层的卷积神经网络
				 用它进行了 "邮政编码" 的识别。//手写体识别
                 
                 最开始 Lenet5  准确率不高，后面不断调整优化，准确率比 支持向量机 更高的
                 最初 Lenet5 并不火，
                 
                 直到了2006年杰弗里*辛顿（深度学习三巨头之一）"第三波AI浪潮" 
                 
                 
                 //===================================== ImageNet
                 2010，2011 参加比赛的，得奖者都是机器学习，
                 
                 2012 年杰弗里*辛顿和它的学生做出了 AlexNet（也是CNN,8层），
                 拿了冠军，错误率在15.7%
                 
                 2012年之后，就没有传统的机器学习去参加这两个比赛了
                 
                 2014年 VGG19(16-19层) 亚军 7.3%
                 2014年 GoogleNet22层 冠军  6.7%
                 
                 2015年  ResNet152层， 3.57%    人的错误率是：5%
                     
                 后来，这个CNN 1017 层了
                 
                 再后来这个比较没有再举办了，因为它无法再提升了。