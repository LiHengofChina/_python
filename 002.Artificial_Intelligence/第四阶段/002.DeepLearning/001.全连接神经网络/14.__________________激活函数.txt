

//================================================================ 什么是 "激活函数"
//================================================================ 什么是 "激活函数"

在 "神经网络" 中，将 "输入信号" 的总和转换为 "输出信号" 的函数被称为 "激活函数（ activation function）"


	/**

	每一个 "神经元" 算完之后，把它的值 交给另一个函数算一下，这个函数就叫 "激活函数"。

	如，某一次：神经元算出来是 -5，那么
		1 /( 1 + e^(-5))  次方，才是它的结果

	*/




//================================================================ 为要什么要使用 "激活函数"
//================================================================ 为要什么要使用 "激活函数"
 
"激活函数" 将 "多层感知机输出" 转换为 "非线性"，
使得 "神经网络" 可以 "任意逼近任何非线性函数"，这样 "神经网络" 就可以应用到 "众多的非线性模"


//===============================================
//===============================================

MLP: 多层感知机
NN： neuron，神经网络
很多关于框架，关于神经网络的接口，都放在nn模块下，
怎么区别它们？




（1）如果一个多层网络，使用 "连续函数" 作为激活函数的多层网络，称之为 "神经网络"
		//大部分是连续的
（2）否则称为 "多层感知机"

所以 "激活函数" 是区别 "多层感知机" 和 "神经网络" 的依据。



//================================================================ 常见 "激活函数"
//================================================================ 常见 "激活函数"
//=======================（1）阶跃函数
//=======================（1）阶跃函数

最简单的，小于等于零是0，大于零是1

f(x) = 1( x >= 0 )

f(x) = 0( x < 0 )



//=======================（2）sigmoid函数（Logistic函数）
//=======================（2）sigmoid函数（Logistic函数）

用于隐层神经元输出


表达式： 1 /( 1 + e^(-5)) 


优点：易于求导
缺点：反向传播时，容易出现梯度消失的情况。

	  这样就无法让网络达到很深的层次。


		网络无法做到太深：
		所以浅层网络才会用这个，深层网络不会用这个。




//=======================（3）tanh 双曲正切函数
//=======================（3）tanh 双曲正切函数

( 1 - e^(-2*x))  / ( 1 + e^(-2*x)) 	
		和逻辑函数有点像


优点：易于求导，比sigmoid函数更快。



//=======================（4） ReLU（Rectified Linear Units，修正线性单元）
//=======================（4） ReLU（Rectified Linear Units，修正线性单元）

（1）ReLU（Rccitified Linner Units，修正线性单元）

	f(x) =   x(x>0), 大于0，返回 x，	//永远有一个梯度

	f(x) =   0(x<=0)，小于0 ，返回0，

（2）常用一于图像，因为图像是 0-255 ，没有负数
		//这是在隐含层

//=======================（4） Softmax
//=======================（4） Softmax

图像 在输出层：常用softmax，
			它的作用是将 "输出结果" 转成 "相对概率"。

		/**
			当我拿到一张图的 "4个像素值" ，我要判断这张图里面是谁的时候，
			这是一个分类问题，

			在分类任务中，要分几个类别，在 "输出层" 就有几个神经元。

			因为 "神经网络" 是一个 "大的线性模型"， 配合一个 "激活函数" ，它算出来一定是一个数值。
 
		*/

如：神经元算出来是 1.2
那么：soft max的概率就是：

e^1.2 /(e^1.2 + e^4.0 +e^0.2) ，最后算出概率



"分类业务" 的 "输出层" 常用softmax


