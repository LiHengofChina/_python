

//========================================================= 关联规则
//========================================================= 关联规则


Apriori	（使用多，用法简单）
		//比较出名，沃尔玛超市，当时聘请了IBM 作为商业顾问，
		//通过所有用户在POS机上面的购物小票，他们找到了有两个风马牛不相及的商品
		//经常会被一起购买：啤酒 和 尿布
		//弊端：多次遍历数据库

FPGROWTH
		//对 Apriori 的升级版，它只需要遍历数据库两次，就能得到想到的结果。、
		//效率有所提升，它通过树形结构来保存商品


//====================== Apriori
//====================== Apriori

	//================= 背景
	//================= 背景
	"共现矩阵" 能解决：啤酒 和 尿布 的问题，统计 "每个商品" 和 "另一个商品" 共同出现的次数。
	但是在处理，哪3个商品一起出现，哪4个商品一起出现，可能就会有一点点小问题了。

	//================= 
	//================= 
	通过分析 "购物篮（购物小票）"中的 "商品集合"，
	从而找出商品之间 "关联关系" 的 "商品集合"，
	从而找出商品之间关联关系的关联算法。

	//================= 目标： 总是寻找一起出现的商品
	//================= 目标： 总是寻找一起出现的商品

	//============ 支持度
	//============ 支持度
	假如： mahout实战 ————> 机器学习实战 两本书经常一起出现

		如果总共有100个小票，其中28个小票一起出现了《mahout实战》和《机器学习实战》
		那么它的们支持度就是：28%
		其实就是一起出现的百分比。

	//============ 置信度
	//============ 置信度

		买了《mahout实战》与《机器学习实战》一起购买的记录数，
		占所有购买《mahout实战》记录数的比例————置信度（局部），
		需要达到一定的阈值。

		如果总共有100个小票，50个人买了 mahout实战，
		28 个小票一起出现了《mahout实战》和《机器学习实战》

		28/50 就是置信度


		置信度越高 ，两本书一起出现的概率越大

		置信度最高时，买了mahout实战的人，都买了机器学习实战 ，就是 50/50

		置信度越高，越应该推荐

	//============ 项集、K项集
	//============ 项集、K项集

	 项的集合：2件商品、3件商品，有哪些组合

	//============ 项集频率
	//============ 项集频率
		哪些组合 出现的次数

	"相对支持度" 就是：支持度 的计算方法
				//一起出现的次数  除以 总的次数

	"绝对支持度"：假设它们2个一起出现了108次，它的绝对支持度就是108

	//============ 频繁项集
	//============ 频繁项集
	频繁项集：经常一起出现的商品
				要设置一个 "最小支持度"，
				高于 "最小支持度" 就是频繁的
				低于 "最小支持度" 就是不频繁的

				//在  "频繁项集" 的基础上过滤置信度 
				//如果这时还能满足置信度，那么它就是一个 "强关联规则"

				//A B 两个商品，满足 "最小支持度"，就是 "频繁项集"
				//A对B的置信度是80%，我们就说它们是 "强关联规则"，
				//那么在购买A的时候，一定会推荐B


	//============ 问题
	//============ 问题

	A到C 和 C到A 的支持度是一样的，
					
	但是A到C 和 C到A 的置信度是不一样的。
			//买了A 有66%的几率推荐C
			//买了C 有100%的几率推荐A

			//就像是买了电脑、我一定会推荐鼠标
			//买了鼠标，我不一定会推荐电脑。




	//================================================================================== 示例分析：
	//================================================================================== 示例分析：

	//==================== 小票清单
	//==================== 小票清单
	10 买了 A、C、D
	20 买了 B、C、E
	30 买了 A、B、C、E
	40 买了 B、E

	//==========
	项集有K项集，它有1项集、2项集、K项集
	需要一个一个做：

	//=============
	有1项集：一个商品出现的情况
						//统计它的支持度是多少，
								可以使用相对支持度：出现次数 / 样本总数
								也可以用绝对支持度：出现次数
					// 我们使用：绝对支持度,得到1项集的候选集：C1
					{A}: 2
					{B}: 3
					{C}: 3
					{D}: 1
					{E}: 3
					// 最小支持度设置: 根据业务需求设置，sup_min，最小支持度为 2，
					// 然后通过  "最小支持度的过滤" 就得到了，"1项集的频繁集": L1
					{A}: 2
					{B}: 3
					{C}: 3
					{E}: 3

	有2项集：两个商品一起出现的情况
					// "通过 1项集的 频繁项集" 生成 "两个商品"的组合有哪些情况
					{A,B}
					{A,C}
					{A,E}
					{B,C}
					{B,E}
					{C,E}
					// 再统计每两个商品组合出现的情况
					{A,B}：1
					{A,C}：2
					{A,E}：1
					{B,C}：2
					{B,E}：3
					{C,E}：2
					// 再过滤  "电小支持度" sup_min = 2 ,得到 "2项集的频繁项集"
					{A,C}：2
					{B,C}：2
					{B,E}：3
					{C,E}：2
	有3项集：三个商品一起出现的情况
					//依次类推
					......
	//================= 所以是：
	//================= 所以是：
	通过上一个项集的 "频繁项集"，
	生成下一个项集的 "候选项集"，
	通过循环来实现的。
	//================= Apriori 的接口
	//================= Apriori 的接口

	在构建某些算法 ，要部署到服务器上面的时候，最靠谱的还是自己手动还原出来


	//=================  每一个 "项集"，它都有自己的 "项集"
	//=================  每一个 "项集"，它都有自己的 "项集"


//===============-================================ FPGROWTH
//===============-================================ FPGROWTH
	Apriori 多次描述数据库
	巨大数量的候补项集
	繁琐的支持度计算


	FPGROWTH 改善Apriori
	//========================
	FPGROWTH 只扫描两次数据库

	第1次：获得单个项目的频率，去掉不满足支持度要求的项，
		   并对剩下的项排序。
		   //单个项目就是指1项级
	第2次扫描的时候，建立一颗FP-Tree树。
		   //使用树形结构来保存数据

	//======================== 指标：
	支持度："一起出现的数量" ，占 "总样本数量的比例"。

	置信度：买了A商品的人，同时买了B商品的人有多少。
				AB / A

	"支持度和置信度"之间有一些简便的运算方法
	......

	只要知道支持度，就能算出置信度。

	//======================== FPGROWTH
	FPGROWTH 它的目的也是找到频繁项集

		主要区别是 "保存数据的方式不一样"

	//======================== 步骤：
	第一步：每项商品按频数递减排序，删除频数小于最小支持度MinSup的商品。
		如：F1中的排序
			薯片:7
			鸡蛋:7
			面包:7
			牛奶:6
			啤酒:4
 	第二步：对于 "每一条购买记录" ，按照F1中的顺序重新排序。
			//按上面的排序

			重新排序之后，用，树形结构保存数据


