

//=========================== 语言模型
//=========================== 语言模型

它能根据前一个词预测出下一下词是什么

//CHAT GPT 就是词语接龙，它是一个生成模型，
//它是大语言模型  LLM

语言模型的两种解释：
（1）计算句子的概率
（2）根据前面N个词预测下一个词





//=========================== （1）N-gram模型
//=========================== （1）N-gram模型



一个句子中，距离越远的词关系越弱，越近的时，才是关系越强的
			//所以只考虑一定范围内容的词
			//N-gram模型就是这样一个模型

			当 N=1 时，就好像每个词是不相互影响的。
			当 N=2 时，就只考虑前一个词，这个就叫二元模型。
			当 N=3 时，称为三元模型。

			N越长，


//=========================== （2）神经网络模型
//=========================== （2）神经网络模型

它还是一个N元结构：

神经网络语言模型（NNLM）

NNLM是利用视角网络对N元条件进行概率估计的一种方法，

它还是 "根据前面几个词" 根据神经网络，预测出下一个词，


它是一个全连接网络，
自然语言处理里面很少有卷积出现。


//=========================== （3）Word2vec
//=========================== （3）Word2vec

Word2vec 库：专门用于词嵌入训练库
Word2vec是Goolge发布的、应用最广泛的词嵌入表示学习技术

（1）CBOW 连续词袋模型	
		呼伦贝__大草原
（2）Skip-gram:跳字模型，根据中心词预测上下文	//更强
		______尔_____
		//=================================================== 案例：训练词向量
		//=================================================== 案例：训练词向量
		训练语料库：利用维基百科，训练语料库。
		gensim
		
		（1）登陆
			https://aistudio.baidu.com/aistudio/index

			13688007165/liheng_liheng
			liheng520
		（2）创建项目时添加数据集：
				中文维基百科语料库

		（3）【1】安装gensim库

				!pip install gensim==3.8.1 # 如果不在AIStudio下执行去掉前面的叹号

				//安装之后就有了 data104767

			 【2】执行读取数据的部分

			 【3】训练

			 【4】保存模型

			 【5】推荐


（3）RNN

		（1）原生RNN，具有短期的记忆能力
		（2）长短期记忆模型（LSTM）
				它有3个子神经网络
				输入门：
				遗忘门：
				输出门：
		（3）双向循环神经网络：
				我喜欢苹果，比安卓用起来更流畅些
				我喜欢苹果，基本上每天都要吃一个

