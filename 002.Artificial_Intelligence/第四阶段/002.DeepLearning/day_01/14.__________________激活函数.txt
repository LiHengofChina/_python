

//================================================================ 什么是 "激活函数"
//================================================================ 什么是 "激活函数"

在 "神经网络" 中，将 "输入信号" 的总和转换为 "输出信号" 的函数被称为 "激活函数（ activation function）"


	/**

	每一个 "神经元" 算完之后，把它的值 交给另一个函数算一下，这个函数就叫 "激活函数"。

	如，某一次：神经元算出来是 -5，那么
		1 /( 1 + e^(-5))  次方，才是它的结果

	*/




//================================================================ 为要什么要使用 "激活函数"
//================================================================ 为要什么要使用 "激活函数"
 
"激活函数" 将 "多层感知机输出" 转换为 "非线性"，
使得 "神经网络" 可以 "任意逼近任何非线性函数"，这样 "神经网络" 就可以应用到 "众多的非线性模"


//===============================================
//===============================================

MLP: 多层感知机
NN： neuron，神经网络
很多关于框架，关于神经网络的接口，都放在nn模块下，
怎么区别它们？




（1）如果一个多层网络，使用 "连续函数" 作为激活函数的多层网络，称之为 "神经网络"
		//大部分是连续的
（2）否则称为 "多层感知机"

所以 "激活函数" 是区别 "多层感知机" 和 "神经网络" 的依据。



//================================================================ 常见 "激活函数"
//================================================================ 常见 "激活函数"
//=======================（1）阶跃函数
//=======================（1）阶跃函数

最简单的，小于等于零是0，大于零是1

f(x) = 1( x >= 0 )

f(x) = 0( x < 0 )



//=======================（2）sigmoid函数（Logistic函数）
//=======================（2）sigmoid函数（Logistic函数）

用于隐层神经元输出


表达式： 1 /( 1 + e^(-5)) 


优点：易于求导
缺点：反向传播时，容易出现梯度消失的情况。







//=======================（3）tanh双曲正切函数
//=======================（3）tanh双曲正切函数



