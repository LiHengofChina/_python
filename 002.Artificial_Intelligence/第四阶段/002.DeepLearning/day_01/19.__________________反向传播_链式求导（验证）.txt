
//===================================================== 复合函数
//===================================================== 复合函数
有 复合函数：

	t = x + y 
	z = t^2


现在可以求  ∂z/∂t      //z关于t的导数
也可以求    ∂t/∂x	   //t关于x的导数


怎么求  ∂z/∂x       	//z关于x的导数


因为：
		  =  ∂z/∂t * ∂t/∂x
		  =  "z关于t的导数" * "t关于x的导数" //同项约分， 
		  =  ∂z/∂x  //就得到了 "z关于x的导数"

所以:  ∂z/∂x = ∂z/∂t * ∂t/∂x
			 =  2t  //z关于t的导数 ：t^2：指数乘以系数，再降次，就是2t
				* 
				1   // t关于x的导数是 1	 
			 =  2t	//t = x+y ，把x+y带进去
			 =  2 * ( x + y )	//这就是z关于x的导数表达式。



//=====================================================
//=====================================================
深度神经网络里面的核心就是 "链式求导法"


因为输出层有梯度，前面很多层都要求梯度

从后面一个一个链过去，一个一个乘过去。

没发直接作用于前面，就一个一个乘过去
//z没有办法直接求出关于x的导数，就先算t的，再乘以t关于x的


//================================================================================= 验证：加法节点的偏导是1，乘法节点偏导是另一条边
//================================================================================= 验证: 加法节点的偏导是1，乘法节点偏导是另一条边

 
z = wx + b

//==========正向

（1）y = w * x

（2）z = y + b

现在求 ∂z/∂w 的偏导


//====================
因为： ∂z/∂y * ∂y/∂w = ∂z/∂w 


∂z/∂y  = 1

∂y/∂w  = 1 * x * w^1 = x //指数 * 系数，再降次。

∂y/∂x  = 1 * x^1 * w = w //指数 * 系数，再降次。


所以  ∂z/∂y * ∂y/∂w  =  1 * x = x


加法节点的 "偏导是1"，乘法节点 "偏导是另一条边"


