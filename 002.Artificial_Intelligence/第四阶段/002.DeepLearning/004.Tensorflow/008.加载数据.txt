


tensorflow加载数据更加复杂一些，
因为 "深度神经" 对加载数据要求更高了


sklearn 也有自己读取数据方向。
numpy里面也有。

//================================================ 深度学习中，"文件读取" 机制
//================================================ 深度学习中，"文件读取" 机制


（1）第一步：将要 "读取的文件" 放入 "文件名队列" 。FIFO


（2）第二步：读取文件内容，并实行解码。
				// 读取的是字符串，转成张量

				// 文本文件   ——————> 读取字符串	 ——————> 转成张量
				// 二进制文件 ——————> 读取的是字节串 ——————> 转成张量


（3）第三步：批处理，按照指定笔数构建成一个批次取出。
				//需要多少个，生成多少个。
				//分批次送出。





//================================================= 
//================================================= 


机器学习中数据要求：
		（1）随机，不能有顺序。
		（2）快，  多进程读取。
		（3）批量，文件大小比较小，但是数量多，不是一次读取全部，

//=============================================================================
//=============================================================================


（1）文件队列构造：
	   生成一个先入先出的队列，文件阅读器会需要它来读取数据
	   tf.train.string_input_producer(string_tensor,shuffle=True)
	   string_tensor:含有文件名的一阶张量
	   shuffle: 是否打乱文件顺序
    返回：文件列

（2）文件读取API：
		（ 2.1 ）tf.TextLineReader //读取CVS文件，默认按行读取
				 //文件行读取器。

		（ 2.2 ）二进制文件读取：
				 //tf.FixedLengthRecordReader(record_bytes)
				 //读取每个记录是固定字节的二进制文件
				 //record_bytes: 每次读取的字节数。
				通过读取文件：read(file_queue)
				 //从队列中读取指定数量（行，字节）的内容
				 //返回值：一个tensor元组（文件名，value）
							//表示从哪个文件读取的值。
							//

		（ 2.3 ）图像读取器，一次读取 "一张图片"，作为一个样本
				 //还是先构建文件队列，只不过每次存放的是一张一张的图片

				 //图像解码后一定是三维数组

				 //批处理要求：每张图片的大小必须一样。
							   //因为读取的图像要交给卷积神经网络
							   //卷积神经网络要求 "每张图片大小" 要一样


