# 三、数据预处理

## 1. 数据预处理的目的

1）去除无效数据、不规范数据、错误数据

2）补齐缺失值

3）对数据范围、量纲、格式、类型进行统一化处理，更容易进行后续计算

```


一组 "好的数据"，可以建立 "好的模型"。

一组 "不好的数据"，一定不能建立 "好的模型"


```



## 2. 预处理方法

### 1）标准化（均值移除）

```java


一组 "好的数据"，可以建立 "好的模型"。

一组 "不好的数据"，一定不能 "建立好"


//====================================================== 数据预处理的目的
//====================================================== 数据预处理的目的

（1）
（2）
（3）对数据的范围、量纲、格式、类型进行统一处理，更容易进行后续计算

//====================================================== 预处理方法
//====================================================== 预处理方法
	（1）标准化（也叫：均值移除 ）
			让样本矩阵中的  " 每一列的平均值为0" ， "标准差为1" ，
			目的：缩小列与列之间的差异？
				//以 "列" 为单位

			/**
				应用场景： 列与列之间差异太大
				如：根据  "身高" 和 "体重"，预测身体健康指数。

				身高（1.6m ~ 1.8m） 			//这个是个位
				体重（50 ~ 100kg）				//这个是10位，
				y = w1x1 + w2x2 + b
				让 模型学习，倾向于差异比较大的一边。也就是体重
				不是说 "体重" 本身 不是对健康影响就大于身高吗

				但是如果变化一下数据：

				身高（1600mm ~ 1800mm） 		//这个是千位
				体重（50 ~ 100kg）				//这个是10位，

				身高以 mm为单位，这样就化了， 

				所以 "标准化" 的目的就是要解决这个问题：
				目的：消除数据本身，"特征" 与 "特征" 差异过大的情况

				特征 与 特征 之间处理成同一个 "数值量级单位"。
				这样  "机器学习" 的结果就会 "更加准确"

			*/

			/** 具体步骤

			1. 用当前列的数据 - 当前列的平均值，得到 "离差"
					//因为每个值是：真值 + 误差 ，减去平均值就是误差，误差加一起就是0
			2. 用 "离差" / 原始数据的每列的标准差，就会变成标准差为1的情况。
					//通过数学公式可以证明，这里就不证明了。

				17   230   5600
				20   320   6800
				23   660   7200

			*/

			//============================================
			//============================================
			机器学习中有一个框架叫: sklearn
			在它里面有一个 preprocessing 库 //数据预备处接口都在这里面
			res = sp.scale(raw_sample)		//接口
			//============================================
			//============================================


```

让样本矩阵中的每一列的平均值为0，标准差为1. 如有三个数a, b, c，则平均值为：

$$
m = (a + b + c) / 3 \\
a' = a - m \\
b' = b - m \\
c' = c - m
$$
预处理后的平均值为0：
$$
(a' + b' + c') / 3 =( (a + b + c) - 3m) / 3 = 0
$$
预处理后的标准差：$s = sqrt(((a - m)^2 + (b - m)^2 + (c - m)^2)/3)$

$a'' = a / s$

$b'' = b / s$

$c'' = c / s$

$$s'' = sqrt(((a' / s)^2 + (b' / s) ^ 2 + (c' / s) ^ 2) / 3) $$

   $=sqrt((a' ^ 2 + b' ^ 2 + c' ^ 2) / (3 *s ^2))$

   $=1$

标准差：又称均方差，是离均差平方的算术平均数的平方根，用σ表示 ，标准差能反映一个数据集的离散程度

代码示例：

```python
# 数据预处理之：均值移除示例
import numpy as np
import sklearn.preprocessing as sp

# 样本数据
raw_samples = np.array([
    [3.0, -1.0, 2.0],
    [0.0, 4.0, 3.0],
    [1.0, -4.0, 2.0]
])
print(raw_samples)
print(raw_samples.mean(axis=0))  # 求每列的平均值
print(raw_samples.std(axis=0))  # 求每列标准差

std_samples = raw_samples.copy()  # 复制样本数据
for col in std_samples.T:  # 遍历每列
    col_mean = col.mean()  # 计算平均数
    col_std = col.std()  # 求标准差
    col -= col_mean  # 减平均值
    col /= col_std  # 除标准差

print(std_samples)
print(std_samples.mean(axis=0))
print(std_samples.std(axis=0))
```

我们也可以通过sklearn提供sp.scale函数实现同样的功能，如下面代码所示：

```python
std_samples = sp.scale(raw_samples) # 求标准移除
print(std_samples)
print(std_samples.mean(axis=0))
print(std_samples.std(axis=0))
```

### 2）范围缩放

```java
 

	（2）范围缩放
		 将每一列的 "最小值" 和 "最大值" 设定为  "相同的区间"
		 最小值一般设置为0，最大值设置为1。
		 中间值 "同比利" 缩放
		 //将  "每列的值" 处理成 "相同的数值范围"
		 //常用区间 "0~1" 
			/**
			17
			20
			23

				具体做法：
						（1）每一个值都减去最小值
							17	- 17	= 0
							20	- 17	= 3
							23	- 17	= 6
						（2）然后再除以 "列的极差"//np.ptp() 最大值减最小值就是极差。
							17	- 17	= 0
							20	- 17	= 3
							23	- 17	= 6
			*/



			/**
				 "范围缩放"  和 "均值移除" 他们的 "应用场景" 是相同 的，

				 范围缩放 也是用来处理  "列与与差距过大" 的情况
				 只不过 "范围缩放" 的处理方式不一样
			*/
 
 			//============================================
			//============================================
			同样可以使用 sklearn 框架来实现这个功能
			mms = sp.MinMaxScaler(feature_range=(0,1)) 
							#定义 "范围缩放器对象"
							#feature_range=(0,1) 意思是 最小值0，最大值为1

			mms_sampeles = mms.fit_transform(raw_samples)#缩放
								/***
									fit_transform 本质是2个操作
									fit 适配 、匹配、训练
									transform 转换
									
									相当于:
										mms.fit(raw_sample)
										res = mms.transform(raw_sample)
										它们两个参数一样，所以把它合并到一起了

									但是某些场景必须分开写

								*/

			print(mms_sampeles)

			//============================================
			//============================================

```

将样本矩阵中的每一列最小值和最大值设定为相同的区间，统一各特征值的范围.如有a, b, c三个数，其中b为最小值，c为最大值，则：
$$
a' = a - b
$$

$$
b' = b - b
$$

$$
c' = c - b
$$

缩放计算方式如下公式所示：

$$
a'' = a' / c'
$$

$$
b'' = b' / c'
$$

$$
c'' = c' / c'
$$

计算完成后，最小值为0，最大值为1.以下是一个范围缩放的示例.

```Python
# 数据预处理之：范围缩放
import numpy as np
import sklearn.preprocessing as sp

# 样本数据
raw_samples = np.array([
    [1.0, 2.0, 3.0],
    [4.0, 5.0, 6.0],
    [7.0, 8.0, 9.0]]).astype("float64")

# print(raw_samples)
mms_samples = raw_samples.copy()  # 复制样本数据

for col in mms_samples.T:
    col_min = col.min()
    col_max = col.max()
    col -= col_min
    col /= (col_max - col_min)
print(mms_samples)
```

我们也可以通过sklearn提供的对象实现同样的功能，如下面代码所示：

```Python
# 根据给定范围创建一个范围缩放器对象
mms = sp.MinMaxScaler(feature_range=(0, 1))# 定义对象(修改范围观察现象)
# 使用范围缩放器实现特征值范围缩放
mms_samples = mms.fit_transform(raw_samples) # 缩放
print(mms_samples)
```

执行结果：

```
[[0.  0.  0. ]
 [0.5 0.5 0.5]
 [1.  1.  1. ]]
[[0.  0.  0. ]
 [0.5 0.5 0.5]
 [1.  1.  1. ]]
```

```javascript



//=================================================================== 上面两个统称
//=================================================================== 上面两个统称
/**
"范围缩放" 的 "均值移除" 统称为  "特征归一化"
		（1）线性函数归一化（范围缩放）
		（2）零均值归一化（均值移除）
*/



//========== 这两个都处理列与列的
//========== 这两个都处理列与列的
（1） 标准化、零均值归一化（均值移除）
	  让样本矩阵中的  " 每一列的平均值为0" ， "标准差为1" ，
		标准化值= (当前值−均值)/标准差
	  //主要用于那些 "特征的分布接近正态分布" ，
	  //或者我们希望将它们转 "换为正态分布" 的情况。


（2） 这种算法叫：线性函数归一化（范围缩放），处理  "列与与差距过大" 的情况
	  将每一列的 "最小值" 和 "最大值" 设定为  "相同的区间"
	  最小值一般设置为0，最大值设置为1。
	  中间值 "同比利" 缩放
		归一化后的特征值 = （当前值 - 最小值）/ （最大值 - 最小值）

	  //这种方法尤其适用于那些特征的分布不是正态分布的情况，
	  //或者 "最大" 和 "最小值" 的差异非常大的情况。





```



### 3）归一化

```java
 
		
	//这是另一种归一化方法，通常称为L1和L2范数归一化。
	（3）归一化 normalize
			/**
				反映"样本中" 的 "各个特征" 所占 "比率"，
						用  "每个样本"  的 "每个特征值"，
						除以  "该样本"  各个  "特征值的绝对值" 之和，变换后的样式矩阵
			*/

			/** 示例：

				年份		python(万人)		Java(万人)		PHP(万人)
				2017		10					20				5
				2018		8					10				1

				虽然2018年python的人数下降了，但是总占比上升了。
			*/


			把数值转成占比的一个样式，
			求 "每一行的占比"	//一般求以：每行占比
			也可以求 "每一列的占比"，
			一般对加上绝对值。
			//===============
			sklearn接口
			sp.normalize(原始样本，norm='12')

			/**
				norm 指范数
				# l1:  l1范数，除以向量中 "各元素绝对值之和"
				# l2:  l2范数，除以向量中 "各元素平方之和"

				绝对值 和 平方都是为了防止负数
			*/



//========== 这个是关注行的
//========== 这个是关注行的

（1）归一化 normalize、这是另一种归一化方法，通常称为L1和L2范数归一化。
	L1范数归一化：  "每个特征值" 除以  "整个样本的特征值的绝对值之和"。
					            x / ( |d| + |e| + |f|)
	L2范数归一化：  "每个特征值" 除以 "整个样本的特征值的平方和" 的 ”平方根“。
							    x / sqrt((d)^2 + (e)^2 + (f)^2)



```

反映样本所占比率.用每个样本的每个特征值，除以该样本各个特征值绝对值之和.变换后的样本矩阵，每个样本的特征值绝对值之和为1.例如如下反映编程语言热度的样本中，2018年也2017年比较，Python开发人员数量减少了2万，但是所占比率确上升了：

| 年份 | Python（万人） | Java（万人） | PHP（万人） |
| ---- | -------------- | ------------ | :---------- |
| 2017 | 10             | 20           | 5           |
| 2018 | 8              | 10           | 1           |

归一化预处理示例代码如下所示：

```Python
# 数据预处理之：归一化
import numpy as np
import sklearn.preprocessing as sp

# 样本数据
raw_samples = np.array([
    [10.0, 20.0, 5.0],
    [8.0, 10.0, 1.0]
])
print(raw_samples)
nor_samples = raw_samples.copy()  # 复制样本数据

for row in nor_samples:
    row /= abs(row).sum()  # 先对行求绝对值，再求和，再除以绝对值之和

print(nor_samples) # 打印结果
```

在sklearn库中，可以调用sp.normalize()函数进行归一化处理，函数原型为：

```Python
sp.normalize(原始样本, norm='l2')
# l1: l1范数，除以向量中各元素绝对值之和
# l2: l2范数，除以向量中各元素平方之和
```

使用sklearn库中归一化处理代码如下所指示：

```Python
nor_samples = sp.normalize(raw_samples, norm='l1')
print(nor_samples) # 打印结果
```



### 4）二值化

```
 

	（4）二值化
			 根据一个事先给定的阈值，用0或1 来表示特征值是否超过阈值，

			 阈值 是根据业务需要设置的

			 //注意：主要用来处理  “图像”
			 会导致编码信息损失，是 "不可逆的数值转换" ，
			 所以它主要使用在 图像处理上面，

			 //
			 /**
				//===================== 为什么要用0或1，
				因为机器学习效率更高，算起来更快
			 */
			//===============
			sklearn 接口
			bin = sp.Binarizer(threshold=59) #创建 "二值化对象"（注意边界值）
											 #threshold是域值
			bin_samples = bin.transform(raw_samples) #二值化预处理
										/**
											直接 transform  ，不需要训练
											
											范围缩放，是一个线性的，
											带值进去，才能得到模型，所以需要训练
											
											而二值化，里面使用一个if就可以了，
											所以不需要训练
											
										*/
			print(bin_samples)


 
```

根据一个事先给定的阈值，用0和1来表示特征值是否超过阈值.以下是实现二值化预处理的代码：

```Python
# 二值化
import numpy as np
import sklearn.preprocessing as sp

raw_samples = np.array([[65.5, 89.0, 73.0],
                        [55.0, 99.0, 98.5],
                        [45.0, 22.5, 60.0]])
bin_samples = raw_samples.copy()  # 复制数组
# 生成掩码数组
mask1 = bin_samples < 60
mask2 = bin_samples >= 60
# 通过掩码进行二值化处理
bin_samples[mask1] = 0
bin_samples[mask2] = 1

print(bin_samples)  # 打印结果
```

同样，也可以利用sklearn库来处理：

```Python
bin = sp.Binarizer(threshold=59) # 创建二值化对象(注意边界值)
bin_samples = bin.transform(raw_samples) # 二值化预处理
print(bin_samples)
```

二值化编码会导致信息损失，是不可逆的数值转换.如果进行可逆转换，则需要用到独热编码.



### 5）独热编码

```java

 
	（5）独热编码 //可逆转换
			 //想让数据可逆，不丢失信息细节，这里就可以使用 "独热编码"
			 //========================================== 使用场景
			 //========================================== 使用场景
			 （1）数据是离散值，才能去做。
						//不是离散值，那位数就是无限的了。//就会产生维度灾难
						//连续数据理论可以傅，但是效率不好
			 （2）稀疏矩阵
			 //==========================================
			 /**
				从名字可以看出它是一个编码：
						就是多个0或1组成的数据，来代表它真实的数据。
			 */

			 //==========================================
			 说 "特征" 就是以列为 "单位"
			 //==========================================
			 根据 "一个特征中" 的 "值的个数" //（这些值是离散值）（不重复值的个数）
											 // 指离散值的个数
			 来建立 "一个由1和若干0" 组成的序列，
			 用来 "序列（动词）" 对 "所有的特征" 值进行编码，

			 //==================
			 例如有如下样本：
				[1 3 2 ]
				[7 5 4 ]
				[1 8 6 ]
				[7 3 9 ]
			第一列：有两个值，1使用10编码，7使用01编码
			第二列：有三个值，3使用100编码，5使用010编码，8使用001编码
			第三列：有四个值，2使用1000编码，4使用0100编码， 6 使用0010编码，9 使用0001编码
				/**
					有几种值，就使用几位长度，其中只有一个1，若干0
				*/
			编码字段，根据特征值的个数来进行编码，通过位置加以区分，通过独热编码后的结果为：
				[10 100 1000]
				[01 010 0100]
				[10 001 0010]
				[01 100 0001]
				//这样做之后，信息没有丢失，且全部是1和0

				//注意：显示效果是这样的
				[[1 0 1 0 0 1 0 0 0]
				 [0 1 0 1 0 0 1 0 0]
				 [1 0 0 0 1 0 0 1 0]
				 [0 1 1 0 0 0 0 0 1]]
				 

			//========================================== 接口
			//========================================== 接口
			one_hot_encoder = sp.OneHotEncoder(
				sparse=FALSE,  #是否采用"稀疏格式"，节约内存，只保存1的位置。 #默认True
				dtype="int32", #默认float64
				categories="auto" #自动编码  #默认 auto   #到底是1转成10，还是7转成10由它决定。
															
			)

			oh_samples = one_hot_encoder.fit_transform(raw_samples) # 编码   #训练并转换
			print(oh_samples)

			print(one_hot_encoder.inverse_transform(oh_samples))#解码#编码器和解码器，必须是同一个
			//==========================================
			//==========================================
				  #稀疏矩阵，只记录是1的位置 ，不记录0的位置。
				  /** 如
						(0, 0)	1
						(0, 2)	1
						(0, 5)	1
						(1, 1)	1
						(1, 3)	1
						(1, 6)	1
						(2, 0)	1
						(2, 4)	1
						(2, 7)	1
						(3, 1)	1
						(3, 2)	1
						(3, 8)	1
				  */
				one_hot_encoder = sp.OneHotEncoder()
				res = encoder.fit_transform(raw_samples) #执行独热编码
				res.toarray()
				如果返回的是：稀疏矩阵，可以通过res.toarray()转换成数组。
			//========================================== 另外说明 ：
			//========================================== 另外说明 ：
			//==========================================
			
			1  3
			7  5
			1  5
			7  3

			10  10
			01  01
			10  01
			01  10
			//===========
			同样是10和01，只要在不同列表达的意思不相同就行，至于它内部如果实现的，可以不用关注


```

根据一个特征中值的个数来建立一个由一个1和若干个0组成的序列，用来序列对所有的特征值进行编码.例如有如下样本：
$$
\left[
    \begin{matrix}
    1 & 3 & 2\\
    7 & 5 & 4\\
    1 & 8 & 6\\
    7 & 3 & 9\\
    \end{matrix}
\right]
$$
对于第一列，有两个值，1使用10编码，7使用01编码

对于第二列，有三个值，3使用100编码，5使用010编码，8使用001编码

对于第三列，有四个值，2使用1000编码，4使用0100编码，6使用0010编码，9使用0001编码

编码字段，根据特征值的个数来进行编码，通过位置加以区分.通过独热编码后的结果为：
$$
\left[

    \begin{matrix}

    10 & 100 & 1000\\

    01 & 010 & 0100\\

    10 & 001 & 0010\\

    01 & 100  & 0001\\

    \end{matrix}

\right]
$$
使用sklearn库提供的功能进行独热编码的代码如下所示：

```Python
# 独热编码示例
import numpy as np
import sklearn.preprocessing as sp

raw_samples = np.array([[1, 3, 2],
                        [7, 5, 4],
                        [1, 8, 6],
                        [7, 3, 9]])

one_hot_encoder = sp.OneHotEncoder(
    sparse=False, # 是否采用稀疏格式
    dtype="int32",
    categories="auto")# 自动编码
oh_samples = one_hot_encoder.fit_transform(raw_samples) # 执行独热编码
print(oh_samples)

print(one_hot_encoder.inverse_transform(oh_samples)) # 解码
```

执行结果：

```
[[1 0 1 0 0 1 0 0 0]
 [0 1 0 1 0 0 1 0 0]
 [1 0 0 0 1 0 0 1 0]
 [0 1 1 0 0 0 0 0 1]]
 
[[1 3 2]
 [7 5 4]
 [1 8 6]
 [7 3 9]]
```



### 6）标签编码

```java


	（6）标签编码
			 将"字符串"转成数值类型
			 "针对离散值去做的"
//======================================================== 标签编码只通报转一维数据

标签编码只能转 "一维数据"
		遇到文件时，一般 一列一列转
//========================================================

		根据  "字符串形式的特征值" 在  "特殊序列" 中的位置，
		来为其  "指定一个数字标签" ，用于提供给基于 "数值算法" 的学习模型

		//=======================================
		//=======================================



//====================== sklearn 框架接口
//====================== sklearn 框架接口

raw_samples = np.array(['bmw','BYD','bmw',
						'benz','BYD','audi'])
						
						
						/**	（1）先按字母序列排序，
								['bmw','BYD','bmw', 'benz','BYD','audi']
								
								a = 97
								b = 98

								A = 65
								B = 66
							（2）再映射
								['BYD','BYD','audi','benz','bmw','bmw']
								 0      0     1        2     3    3
							（3）再按原来位置写值
								['bmw','BYD','bmw', 'benz','BYD','audi']
								  3      0     2       2     0      1

						*/



lb_encoder = sp.LabelEncoder() #定义标签编码对象
lb_samples = lb_encoder.fit_transform(raw_samples) #执行标签编码#训练并转换
print(lb_samples)

print(lb_encoder.inverse_transform(lb_samples)) #逆向转换



//========================================================
//========================================================

将car.txt中的字符串通过 "标签编码" 的形式转成数值类型


	//每一列，必须使用不同的编译器


	注意：预测的时候，同样需要将数据转成 "相同的标签编码形式"


```

根据字符串形式的特征值在特征序列中的位置，来为其指定一个数字标签，用于提供给基于数值算法的学习模型.代码如下所示：

```Python
# 标签编码
import numpy as np
import sklearn.preprocessing as sp

raw_samples = np.array(['audi', 'ford', 'audi',
                        'bmw','ford', 'bmw'])

lb_encoder = sp.LabelEncoder() # 定义标签编码对象
lb_samples = lb_encoder.fit_transform(raw_samples) # 执行标签编码
print(lb_samples)

print(lb_encoder.inverse_transform(lb_samples)) # 逆向转换
```

执行结果：

```
[0 2 0 1 2 1]
['audi' 'ford' 'audi' 'bmw' 'ford' 'bmw']
```



# 四、练习

1）判断以下哪个是回归问题，哪个是分类问题，哪个是聚类问题：

- 判断一封邮件是否为垃圾邮件

- 在图像上检测出人脸的位置
- 视频网站根据用户观看记录，找出喜欢看战争电影的用户

2）分类和聚类主要区别是什么？

3）判断以下哪些是数据降维问题

- 将8\*8的矩阵缩小为4\*4的矩阵
- 将二维矩阵变形为一维向量
- 将高次方程模型转换为低次方程模型

```java

（1）判断以下哪个是回归问题，哪个是分类问题，哪个聚类问题

		判断一封邮件是否为垃圾邮件
			//分类（要么是，要么不是）

		在图像上检测出人脸的位置
			//回归（因为要确定左上角位置，找到：x、y、、宽w、高h，不同人出现的点不同，所以它们是连续的值）
			//      要确定人脸所在的矩形框

		视频网站根据用户观察记录，找出喜欢年战争电影的用户
			//聚类问题


（2） 分类 和 聚类 的主要区别是什么
		分类：有监督、离散数据，有对错。
		聚类：无监督、无对错。


（3） 判断以下哪些是数据降维的问题

		（1）将 8*8的矩阵缩小为4*4的矩阵
				//是
		（2）将二维矩阵变形为一维向量
				//是		
		（3）将高次方程模型转换为低次方模型
				//是 （因为高次方程算起来比较复杂，低次方程算起来容易一些）



```

