
//===================================================== NPL发展历程
//===================================================== NPL发展历程


第一阶段：基于规则
第二阶段：基于统计
第三阶段：基于深度学习



//================== 熵
//================== 熵
		/**
		1948年：
		Shannon把 "离散马尔可夫过程" 的概率模型应用于 "描述语言的自动机"。
		接着，他又把 "热力学中“熵”(entropy)"的概念引用于 "语言处理" 的 "概率算法" 中

		熵-entropy //在  "决策树-分类"中讲过
			衡量 "一批数据、一个系统" 混 乱还是有序的 "程度"。
			越混乱，熵值越高

			如果 "类别越多"，熵值越高，只有一个类别，熵值为0。
			只有一个类别，数据是最纯净的。

			为熵值公式：	∑（P  * log（P））
			log(1)为0，0乘以任何数就得0。
		*/

//================== 时间段
//================== 时间段

~1956：

1957~1970：
			（1）基于规则：语言学家建立模型，设置语法规则，行不通。基于概率，
			（2）基于概率：

1971~1993：
			隐马尔可夫模型

1994~：
			神经网络模型


//===================================================== 困难与挑战
//===================================================== 困难与挑战

（1）歧义
（2）不同语言结构
（3）不可预知


