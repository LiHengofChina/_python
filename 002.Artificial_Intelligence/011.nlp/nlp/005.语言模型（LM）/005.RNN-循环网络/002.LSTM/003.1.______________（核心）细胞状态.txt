 
//================================================== 细胞状态
//================================================== 细胞状态

	在LSTM模型里面，它的核心就是 "细胞状态"，


//================== 什么是细胞状态
//================== 什么是细胞状态

细胞状态 就是： 
		 数据是  "怎么记录的"
		 数据是  "怎么更新的" 等等。

//================= 什么是 "细胞状态的更新"
//================= 什么是 "细胞状态的更新"
细胞状态 是在不断的 "更新迭代中"，

"你能输入进来什么、我要遗忘什么、我最终输出了什么" 

就相当于: "某次细胞状态的更新"，
它永远是在算：我能输入什么、我能丢弃什么、输出什么，不断的更新迭代，保存位置关系，数据顺序等等

这个 "整体的流程" 就是 "LSTM '细胞状态' 的更新"。


用 "贯穿细胞" 的 "水平线" 表示。细胞状态像传送带一样。
它贯穿整个细胞却只有很少的分支，这样能保证信息不变的流过整个RNNs。

//=============================  
//=============================  

细胞状态是 "遗忘门" 和 "输入门" 联动的结果。


//================================================== 细胞状态更新 GPT
//================================================== 细胞状态更新 GPT
//=========== GPT 回答
//=========== GPT 回答
遗忘门：
	遗忘门控制着从细胞状态中遗忘什么信息。
	这是通过 "一个神经网络（我们这里称之为f）" 和 "一个sigmoid激活函数" 完成的，
	这个神经网络基于当前的输入和上一个时刻的隐藏状态来产生一个0到1之间的输出向量。
	这个向量的每个元素对应于细胞状态中每个元素应该 "被遗忘的程度"。

输入门：
	（1）输入门控制着哪些新的信息将被存储在细胞状态中。
	     它涉及两部分：
		  一个是“输入门层”（我们这里称之为i）
		  一个“候选值层”（我们这里称之为~C）。
		  
	（2）  “输入门层”基于当前输入和上一个时刻的隐藏状态，
		 通过另一个神经网络和sigmoid函数，产生一个0到1之间的输出向量，
		 指示 “哪些信息将被更新”。
		 
	（3）“候选值层” 通过 “第三个神经网络和tanh函数”，产生一个“候选的更新向量”，
		 这个向量的每个元素有可能被加到 “细胞状态” 中。

细胞状态更新:
	细胞状态 C_(t−1) 到 C_t  更新是这样的
	（1）首先，上一个时刻的细胞状态通过遗忘门的输出 f 
	（2）然后，输入门的输出i 和 候选值层的输出~C相乘，产生的结果决定了哪些新的信息将被加入到细胞状态中。


细胞状态的更新可以用公式表示为：
因此，细胞状态的更新可以用公式表示为：C_t = f * C_(t−1) +  i * ~C
	//新的状态  =  ((遗忘门输出 f)  *  (上一个状态)) + (输入门输出的“哪些信息将被更新” ) * (输入门输出的“更新向量” ) 


