

//=================================================== 神经网络模型 NNLM
//=================================================== 神经网络模型 NNLM 

它还是一个 "N元结构" ，//但它是用神经网络来实现的

但它是利用 "神经网络"，根据  "前面几个词" ，对 "下一个词做预测"
		//也是 "概率估计"

//======================= 比如：
//======================= 比如：

输入前 3 个词，预测出第 4 个词
输入第 2 3 4 个词，预测出第 5 个词
输入第 3 4 5 个词，预测出第 6 个词


//======================= 重点
//======================= 重点

它还是 "根据前面几个词" 使用 "神经网络" 预测出下一个词，

它是一个 "全连接网络" 


自然语言处理里面 "很少有卷积出现"。


//======================= 示例：
//======================= 示例：

呼伦贝 __ __ __

设词典大小为 1000 ，向量维度为25，N=3，先将前N个词表示成独热向量：
//1000词典里面有1000个词

呼：[1,0,0,0,0,...,0]
伦：[0,1,0,0,0,...,0]
贝：[0,0,1,0,0,...,0]

//========================== 第一层
输入：[3,1000]
权重：[1000,25]  //25：表示希望  "每一个词输出25维的词嵌入"

矩阵相乘：[3,1000] * [1000,25] = [3,25]
//========================== 第二层

输入：[3,25]
权重：[25,1000]
矩阵相乘：[3,25] * [25,1000] = [3,1000]

拍扁[1,1000]
再使用softmax得到1000个概率，
看这1000个概率哪一个最高，预测出来就是哪一个值



