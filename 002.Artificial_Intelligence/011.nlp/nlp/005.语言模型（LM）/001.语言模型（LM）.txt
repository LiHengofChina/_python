
什么是语言模型？
	它能根据 "前面的几个词"，预测出 "下一个词"。//概率模型，其实就是词语接龙


简单说：就是根据 "前面的几个词" 预测 "下一个词"。


//============================================== 示例
//============================================== 示例

呼伦贝 __ __ __


//CHAT GPT 就是词语接龙，它是一个生成模型，
//它是大语言模型  LLM


//============================================== 概念：
//============================================== 概念：

		   P1 P2 P3

	呼伦贝
		   __ __ __

		  //三个字的概率分别是：P1 P2 P3

	把前面三个字的概率和后面的 P1 P2 P3 相乘，这个句子的概率就出来了


语言模型的两种解释
 1） 计算句子的概率
 2） 根据前面N个词，预测下一个词

//========================= 计算句子的概率
//========================= 计算句子的概率


W1 W2 W3 ...... W_n

第1个词  W_1
第2个词  W_2
第3个词  W_3
......
第n个词  W_n

整个句子的概率就是：概率相乘

P(W1) * P(W2|W1) * P(W3|W2W1) * ...... * P(W_n)

/**
（1）
	P(W1) 是可以从 "语料库" 里面统计出来的，

		如：这个词一共出现10次
			整个语料库有1000000个词
			10 / 1000000 就是它的概率

（2）
	P(W2|W1) 在给定W1的条件下，W2的概率是多少

（3）
	P(W3|W2W1) 在给定W1W2的情况下，W3的概率是多少

（4） 一直连乘到W_n就是这个句子的概率





*/

离得越远的词，关系越弱

计算量太大......
		
		


//============================================== 模型
//============================================== 模型


//====================== 传统语言模型
//====================== 传统语言模型




（1）NB贝叶斯模型-------文本分类

（2）SVM支持向量机--------------文本分类

（3）聚类模型


（4）HMM 隐马尔可夫模型---记性标注，语音识别

（5）N-gram模型-------词向量表示

//====================== 深度机器学习
//====================== 深度机器学习


（1）Word2vec ---- "词嵌入" 表示学习技术，是高效获取 "词语的词向量" 


（2）神经网络语言模型（NNLM） NNLM是利用 "神经网络" 对 "N元条件" 进行 "概率估计" 的一种方法
		（1）改进版：CBOW
		（2）改进版：Skip-gram

（3）TextCNN -  文本分类- 
		//文本处理中，卷积比较少

（4）循环神经网络（RNN）
		（1）原生RNN ------------------------ 具有短期记忆
		（2）长短期记忆模型（LSTM）
		（3）双向循环神经网络

（5）ERNIE - 基于Transformer
			----命名实体识别






