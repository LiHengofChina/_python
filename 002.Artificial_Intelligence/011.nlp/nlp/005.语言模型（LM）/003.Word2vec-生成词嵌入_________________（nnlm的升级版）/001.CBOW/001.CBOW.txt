
（1）CBOW 连续词袋模型	 ：根据上下文预测中心词

		呼伦贝__大草原
		//================================== 训练过程
		//假设：呼伦贝尔大草原  //这是一个语料库，只有一句话，实际情况是很大的
		//轮流以 "每个词" 作为 "中心词"
		呼 _ _ 尔大草原		//P(伦|呼) P(贝|呼) 
		_ 伦 _ _ 大草原		//P(呼|伦) P(贝|伦) P(尔|伦) 
		_ _ 贝 _ _ 草原		//P(呼|贝) P(伦|贝) P(尔|贝) P(大|贝)
		呼 _ _ 尔 _ _原		//P(伦|尔) P(贝|尔) P(大|尔) P(草|尔)
		呼伦_ _ 大 _ _		//P(贝|大) P(尔|大) P(草|大) P(原|大)
		呼伦贝 _ _ 草 _		//P(尔|草) P(大|草) P(原|草) 
		呼伦贝尔 _ _ 原		//P(大|原) P(草|原) 

		//输入：N个词
		//输出：1个词

		/**
		把所有概率连到一起，
		写成一个 "条件概率" 联合概率公式：
			P(伦|呼)*P(贝|呼)*P(呼|伦)*P(贝|伦)*P(尔|伦)*P(呼|贝)*P(伦|贝)*P(尔|贝)*P(大|贝)*P(伦|尔)*P(贝|尔)*P(大|尔)*P(草|尔)*P(贝|大)*P(尔|大)*P(草|大)*P(原|大)*P(尔|草)*P(大|草)*P(原|草)*P(大|原)*P(草|原)

		因为这所有搭建和组件在语料库里面是出现过的
		所以我希望，把这个概率 "优化的越大越好"，

		∏ //连成符号

		*/

		/**
			之前说过，可以向两个方向优化：

			表示成损失和误差：越小越好
			表示成概率可能性，越大越好
		*/

		//===========================改进版：负采样


