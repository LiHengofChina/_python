	
//============================================== RAG（Retrieval-Augmented Generation）检索增强
//============================================== RAG（Retrieval-Augmented Generation）检索增强

LLM经过 "训练之后"，对于 "最新的知识" 和 "信息" 就不再能够获取，

另外对于 "内部的一些信息" 和 "知识" 有可能会 "产生幻觉【英文】"，
通过 "retrieval的方法" 能够很好的 "规避这个问题"，

思想非常简单：
（1）通过对query的编码，然后将其与 "外部文档" 进行一个检索，
	  将 "检索的内容" 加入至 "外部文档" 中，
（2）根据 "最新的检索的内容" 和"query的问题"，重新组合传入大语言模型中。


//====================================== 核心
//====================================== 核心
这里的 "核心目标" 是:
	根据 "问题" 找出 文档中 "和问题最相关" 的片段。
	//"文本检索" 里边 "比较常用的" 是 "利用向量" 进行检索，
	我们可以把文档片段全部向量化（通过语言模型，如bert等），
	然后存到向量数据库（如Annoy、 FAISS、hnswlib等）里边，
	来了一个问题之后，也 "对问题语句进行向量化"，以余弦相似度或点积等指标，
	计算在 "向量数据库中" 和 "问题向量最相似" 的 "top k个文档片段"，
	作为 "上文输入" 到大模型中。 "向量数据库" 都支持 "近似搜索功能"。

//======================================
//======================================
另外有研究表示，即使不针对外部的知识，仅仅使用模型内部检索，
对于问题的问答也是有用的

......


