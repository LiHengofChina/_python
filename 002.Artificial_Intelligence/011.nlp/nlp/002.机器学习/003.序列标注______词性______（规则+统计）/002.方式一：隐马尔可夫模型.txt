


//=========================================================== 记性标注模型：
//=========================================================== 记性标注模型：

（1）隐马尔可夫模型（Hidden Markov Model，HMM）
		"时间序列"的概率模型
		当前状态只根  "上一个状态" 有关。

		//这个模型很复杂
		//传统机器 学习中最复杂模型之一

		//马尔可夫链

		//双随机序列

		通过 "看得到的" 推 "测看不到的"

		初始概率：
		转移概率： 转移矩阵	
		发射概率：

		//===================== 解码
		//===================== 解码
		通过 "可见序列" 推断 "隐藏序列" 这个过程叫 解码
		//===================== 解码 使用场景（早期使用很多）
		//===================== 解码 使用场景（早期使用很多）
		（1） 输入一个语音，把语音作为可观测序列，推断后面隐藏文字 ，这个就是语音识别。
		（2） 输入一个词语，输出的是词性，这就完成了记性的标注。

		//===================== HMM的应用：
		//===================== HMM的应用：
		- 语音识别：输入语音序列（观测序列），输出文字序列（隐藏序列）
		- 分词：输入原始文本，输出分词序列
		- 词性标记：输入词语列表，输出词性列表

		//=====================
		//=====================
		//现在用的少，现在主要用循环神经网络

//=========================================================== HMM 和RNN是不是有点像？
//=========================================================== HMM 和RNN是不是有点像？
确实有一些相似之处，尤其是在它们处理序列数据的方式上，但它们在底层原理和具体实现方面有着本质的不同。

相似之处
	（1）序列数据处理：HMM和RNN都是为处理序列数据（如时间序列数据、文本等）而设计的。它们能够考虑到数据点之间的时间依赖性或顺序。
	（2）状态转移：两者都有“状态”概念，能够模拟从一个状态到另一个状态的转移。在HMM中，状态转移是显式建模的，而在RNN中，状态转移是通过隐藏层的递归激活来隐式表示的。


不同之处
	（1）概率模型与神经网络：HMM是一种统计概率模型，它基于概率理论来模拟状态之间的转移以及状态和观测之间的关系。RNN是一种神经网络架构，通过训练权重来学习序列数据的模式，其学习能力不仅限于概率推断。
	（2）参数学习：HMM的学习过程通常涉及到估计状态转移概率、观测概率等统计参数，常用的方法有前向-后向算法等。RNN通过反向传播和梯度下降等方法来调整网络中的权重，以最小化预测误差。
	（3）处理长期依赖的能力：传统的RNN由于梯度消失或梯度爆炸问题，难以处理长期依赖问题。而虽然HMM能够模拟状态之间的转移，但其能力在捕捉长期依赖性方面通常也是有限的。长短时记忆网络（LSTM）和门控循环单元（GRU）是RNN的变种，专门设计来解决长期依赖问题。
	（4）灵活性和表达能力：RNN及其变体（如LSTM和GRU）通常具有更高的灵活性和表达能力，可以捕获更复杂的模式和依赖关系。HMM在某些特定任务上效果很好，尤其是当问题可以自然地用状态转移来建模时，但它的表达能力相对受限。


总的来说，尽管HMM和RNN在处理序列数据方面有相似之处，但它们适用于不同类型的任务，并且在理论和实现上有着明显的区别。选择哪一种模型通常取决于具体任务的需求、数据的性质以及模型的复杂度。


