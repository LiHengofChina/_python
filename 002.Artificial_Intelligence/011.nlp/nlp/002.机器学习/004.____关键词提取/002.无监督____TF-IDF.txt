
//=========================================================== TF-IDF 
//=========================================================== TF-IDF 

（1）TF：词频 : "一个词出现的次数" / "总词语数量"
				//一个词出现 1000 次
				// "总词语" 的数量

				//转换成 0~1 之间的 百分比，相对值
				//另外，出现次数也可以直接叫词频，不作刻意区分


（2）IDF：逆文档频率： 
	 //==================================== 文档频率
	 假设 "语料库" 里面有1000个文档 //文档数量
	 有一个词语出现在100个文档里面
	 100/1000 = 文档 频率
	 //==================================== 逆文档频率 IDF
	 1000/100 = 逆文档频率，这个值比较大，计算不方便

	 在前面加一个log

	 log(1000/100)      //降低数量级

	 log(1000/(100+1))  // +1 防止分母为0 ，拉普拉斯平滑

（3）TF*IDF  //两者相乘

	//====================================语义贡献度
	出现的"次数越多"，出现 "文档越少"，语义贡献度越高。

	/*
		如：贾宝玉、脱氧核糖核酸，非对称加密算法
	*/
	//==================================== python 中的计算示例
	//==================================== python 中的计算示例
	import math
	0.0067 * math.log10(1000/10)

	//==================================== 注意：
	//==================================== 注意：
	需要用到 "语料库" + "停用词表"
	使用 TF-IDF 去计算：计算量大、遍历整个语料库



