
//===================================================== N-Gram
//===================================================== N-Gram

把n个词作为一组， "1个组合" 就是 "1个gram"

所谓 N-gram(N元)模型，就是在计算概率时，
忽略长度大于N的上下文词的影响。



//==================== 基本思想
//==================== 基本思想

N-Gram基本思想是将 "文本里面的内容" 按照 "字节" 进行 "大小为n" 的 "滑动窗口" 操作，
形成了 "长度是n" 的 "字节片段序列"。

然后把 "低频率" 的 "组合"去掉。
然后把 "高频率" 的 "组合"保留。

//==================== N 的取值
//==================== N 的取值
N=1 时，称为 一元模型(Uni-gram Mode)。
N=2, Bi-gram
N=3, Trr-gram

//==================== 例如：I love deep learning
//==================== 例如：I love deep learning

Bi-gram:   //两个词一组
			{I, love}, 
			{love, deep}, 
			{deep, learning}

Tri-gram:  //三个词一组
			{I, love, deep}, 
			{love deep learning}



