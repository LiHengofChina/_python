

总结 "前一页的传播过程"：

	（1）反向 "传播误差"，
				//如果所求 "神经元" 参与了 "两个或多个" 连接计算。
				//则在算这个 "神经元" 误差的时候，要把它们都加起来。

	（2）根据 "误差" 求梯度

//============================================================================ 
//============================================================================

（1）w1 和 w2 需要一个初始值，才能进行参数更新。
			//每一个神经元， 包括B都给它一个初始值。
（2）别忘了激活函数，
	   "在神经元上面"

（3）"正向传播" 能算出它损失函数的值。
//============================================================================== 第一层：隐藏层
//============================================================================== 第一层：隐藏层


//=================================== h1神经元 : 正向计算
//=================================== h1神经元 : 正向计算


i1(0.05)---w1(0.15)----->
						 + b1(0.35)-----> ( net h1 -> out h1 ) 
i2(0.10)---w2(0.20)----->

	//===================================所以：
	(i1(0.05) * w1(0.15)  + i2(0.10) * w2(0.20) ) + b1(0.35) * 1  =  net h1 -> out h1
	= 0.3775 ，带入激活函数 
	= 1 /(1 + e^(-0.3775))
	= 0.593269992



	// b1的初始值是1，b1的权重是0.35

	// net h1 ：net指神经元， net h1 意思是神经元h1
	// 这里有一个激活函数, net h1 交给激活函数处理，
	// 得到 out h1，才是真正的输出。



//=================================== h2神经元 : 正向计算
//=================================== h2神经元 : 正向计算
//同理：

i1(0.05)---w3(0.25)----->
						 + b1(0.35)-----> ( net h2 -> out h2 ) 
i2(0.10)---w4(0.30)----->

out h2 = 0.596884378

//============================================================================== 第二层：输出层
//============================================================================== 第二层：输出层

//=================================== o1神经元 : 正向计算
//=================================== o1神经元 : 正向计算

out h1(0.593269992)---w5(0.40)----->
							+ b2(0.6)-----> ( net o1 -> out o1(0.75136507))  //0.01
out h2(0.596884378)---w6(0.45)----->

//=================================== o2神经元 : 正向计算
//=================================== o2神经元 : 正向计算


out h1(0.593269992)---w7(0.50)----->
							+ b2(0.60)-----> ( net o2 -> out o2(0.772928465)) //0.99
out h2(0.596884378)---w8(0.55)----->



//===========================================================================
//===========================================================================

最后这里输出了两部分： out o1  和  out o2 ，输出两个值，
也就是说：误差有两部分。

//=========================================================================== （重点）
//=========================================================================== （重点）
现在 "输出有了"，
现在可以根据 "输出值" 和 "预测值" 构建 "损失函数"


//============== 损失函数是度量 "真实值" 和 "预测值" 的 差异。
//============== 损失函数是度量 "真实值" 和 "预测值" 的 差异。

损失函数：
	E_total = Σ 1/2(target - output)^2


输出层有 "两个神经元"
"第一个有自己的真实值" 和 "预测值out o1"
"第二个有自己的真实值" 和 "预测值out o2"

所以 "损失函数" 也有两部分，
E_total = Σ 1/2(target - output)^2
E_total = E_o1 + E_o2  	// o1的误差 和 o2的误差//把真值和预测值带入
	    = 0.274811083 + 0.023560026
		= 0.298371109

		//====================================== 这就是损失函数的值，
		//====================================== 这就是损失函数的值，

		我们的目的，就是要求它的极小值。



前面这些就是通过正向传播，算出它的极小值的过程
	
	
//=======================================================================================
//=======================================================================================










