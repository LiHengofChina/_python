

Recurrent Neural Network


//====================================================== 背景
//====================================================== 背景


//（7.11号下午课程的最后时间）和（7.11上午课）

（1）RNN 与 NN 的关系
	 "循环神经网络RNN" 是 针对 "神经网络（NN）" 另一个改进方向

（2）CNN的条件
	 1） CNN要求数据独立，不能处理前后关联的数据。
	 2） CNN要求输入要求等长向量，不能处理变长的数据。


//====================================================== RNN
//====================================================== RNN

（3）RNN 解决的问题// "短期记忆" 能力
		（1）处理：前后有依赖的数据
		（2）处理：变长的数据

（4）RNN模型  "输入" 和 "输出" 对应关系
		一对一、一对多、多对一
		同步多对多、异步多对多

（5）RNN的问题
		短期记忆，不能长期记忆



//====================================================== LSTM
//====================================================== LSTM

（1）LSTM
	 LSTM 是RNN的变种，
	 它的本质是RNN，
	 解决 "RNN梯度消失"。

（2）LSTM 做法
		在RNN的基础上，添加 "子神经网络"。
		//在LSTM中叫做 "门"

（3）LSTM 3 个  "子神经网络"，//三个门
		【遗忘门】1个子网络：决定丢弃什么信
		【输入门】2个子网络：什么信息可以输入进来
		【输出门】决定输出什么

（5）并行计算
	（1）这些门  "并行计算"。
	（2）"并行计算" 有助于 "捕捉长期依赖关系"。



