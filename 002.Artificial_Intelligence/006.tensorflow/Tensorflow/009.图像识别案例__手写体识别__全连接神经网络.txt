
手写体识别：
		比较简单，所以使用 "全连接神经网络"	
		/**
			数据集来自:	MNIST
				http://yann.lecun.com/exdb/mnist/

			通过 tensorflow 的接口，可以自动从上面下载。
			//这组数据主要用于教学目的。

		*/
		/**任务目标：
			（1）根据训练集样本进行模型训练
			（2）保存模型
			（3）加载模型，用于新的手写体数字识别
		*/

		/**
		   使用 "一层" 的 "全连接神经网络" 
		*/
		//================================================ 分析：
		//================================================ 分析：
			（1） 
				 //输出的也是属于每个类别的概率是多少
				 0 [1 0 0 0 0 0 0 0 0 0 ]
				 1 [0 1 0 0 0 0 0 0 0 0 ]
				 2 [0 0 1 0 0 0 0 0 0 0 ]

			（2）一张 28* 28 的灰度图像，
				//它本身是二维数据，
				//但是全连接神经网络只能接受：一维特征
				//所以 28*28 需要拉伸成一维数据 
				//28*28=784也就是一行784列的的一维数据
				所以一幅图像有784个特征

			（3）在输出层有10个神经元， 
				 "权重个数" 就是 [784 , 10]
				 //这里只有一层，直接是输出层
				 // "每个特征(784个)"  和 "每个神经元(10个)" 全连接
				 //所以是 "784行10列" 的权重，(784,10) 


			（4）"一个图像有784个特征 (1,784)" 与 "(784,10) 的权重" 做矩阵相乘
				  (1,784) * (784,10) = (1,10)
				  得到1行10列的值，得到的也就是每个类别的概率

			（5）相乘之后得到：10个值，
					//因为是相乘之后 的结果再加偏置，所以偏置也有10个。

			（6）得到 "每个类别的概率"
			      交给softmax得到相对概率
			（7）找概率的最大值索引，就能得到预测的类别
		//================================================ 相关API
		//================================================ 相关API
		（1）tf.matmul(): 		执行矩阵乘法计算
		（2）tf.nn.softmax():	softmax激活函数	 //net work ，指神经网络
		（3）tf.reduce_sum():   指定维度上求张量和
		（4）tf.train.GradientDescentOptimize(): 优化器，执行梯度下降
		（5）tfargmax(): 返回系统架构最大元素的索引值
		
//================================= 网络结构
//================================= 网络结构


一层全神经连接网络



//=========================================================================	
//=========================================================================	



'''
手写体识别
        模型：全连接神经网络（1层：这一层直接就是输出层）

        MNIST_data 数据说明：
            训练集有 60000 个，测试集有 10000个
            图像是单通道的灰度图像，大小为 28*28 像素

        类别为： 0~9  10个数字

        它是值是转成了10个类别的：相对概率，


最后这个模型的精度：大约是 91% 或 92% 的样子，不能继续提升，
因为这个模型相对来说比较简单了。






